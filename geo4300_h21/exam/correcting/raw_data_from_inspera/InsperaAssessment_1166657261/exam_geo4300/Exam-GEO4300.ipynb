{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam GEO4300\n",
    "\n",
    "## 23. November 2020\n",
    "\n",
    "### Candidat nr. 15415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 Random variable Parameter estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"1a.png\" alt=\"Error\"\n",
    "\ttitle=\"Error\" width=\"450\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"1b.png\" alt=\"Error\"\n",
    "    title=\"Error\" width=\"450\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 Frequency analysis and linear regression\n",
    "\n",
    "The probability to observe at least one 100-years flood or larger with a period of 10 years is 1 minus the probability that it will not happend during the period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability to observe at least one 100-years flood or larger with a period of 10 years is 0.096\n"
     ]
    }
   ],
   "source": [
    "#a )\n",
    "P = 1- (1-(1/100))**10\n",
    "print(\"The probability to observe at least one 100-years flood or larger with a period of 10 years is\", np.round(P,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\n",
    "\n",
    "Assumptions simple linear regression:\n",
    "\n",
    "$\\cdot$ Linearity\n",
    "\n",
    "$\\cdot$ Independence\n",
    "\n",
    "$\\cdot$ Homoscedasticity\n",
    "\n",
    "$\\cdot$ Normality\n",
    "\n",
    "Homoscedasticity is violated in this analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 Confidence interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "n = 30 \n",
    "x = 145\n",
    "var = 20\n",
    "std = np.sqrt(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a)\n",
    "\n",
    "i \n",
    "\n",
    "\n",
    "$\\cdot$ unknown variance \n",
    "\n",
    "$\\cdot$ assume normal distributed\n",
    "\n",
    "\n",
    "$$L = \\overline{x} - t_{1- \\frac{\\alpha}{2}, n-1} s_{\\overline{x}}$$\n",
    "$$U = \\overline{x} + t_{1- \\frac{\\alpha}{2}, n-1} s_{\\overline{x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the estimated variance is 20, the 95% confidence interval on the mean is 143.33 to 146.67\n"
     ]
    }
   ],
   "source": [
    "std_x = std/(np.sqrt(n))\n",
    "t = st.t.ppf(1- alpha/2, n-1)\n",
    "\n",
    "L = x - t*std_x\n",
    "U = x + t*std_x\n",
    "\n",
    "print(\"If the estimated variance is 20, the 95% confidence interval on the mean is\", np.round(L,2), \"to\", np.round(U,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii\n",
    "\n",
    "$\\cdot$ Standard normal distributed\n",
    "\n",
    "$\\cdot$ Known varianse\n",
    "\n",
    "$$L = \\overline{x} - z_{1- \\frac{\\alpha}{2}} \\sigma_{\\overline{x}}$$\n",
    "$$U = \\overline{x} + z_{1- \\frac{\\alpha}{2}} \\sigma_{\\overline{x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the estimated variance is 20, the 95% confidence interval on the mean is 143.4 to 146.6\n"
     ]
    }
   ],
   "source": [
    "z = st.norm.ppf(1- alpha/2)\n",
    "\n",
    "sigma_x = std/(np.sqrt(n))\n",
    "\n",
    "L1 = x - z*sigma_x\n",
    "U1 = x + z*sigma_x\n",
    "\n",
    "print(\"If the estimated variance is 20, the 95% confidence interval on the mean is\", np.round(L1,2), \"to\", np.round(U1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) \n",
    "There is a small diffence between the confidence interval when the variance is estimated and known. The confidence interval is slightly smaller when the varince is known. This difference is a result by a bigger uncertainy when the variance is estimated and not known. In the calculation for confidense interval with an estimated variance we have n samples. When the variance is known, n is much bigger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) \n",
    "\n",
    "chi-square distribution \n",
    "\n",
    "$$L = \\frac{(n-1)s_x^2}{\\chi^2_{1-\\alpha/2, n-1}}$$\n",
    "\n",
    "$$U = \\frac{(n-1)s_x^2}{\\chi^2_{\\alpha/2, n-1}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 95% confidence interval for the variance is 12.69 to 36.14\n"
     ]
    }
   ],
   "source": [
    "x1 = st.chi2.ppf(1-alpha/2, n-1)\n",
    "x2 = st.chi2.ppf(alpha/2, n-1)\n",
    "\n",
    "L2 = ((n-1)*var)/x1\n",
    "U2 = ((n-1)*var)/x2\n",
    "\n",
    "print(\"The 95% confidence interval for the variance is\", np.round(L2,2), \"to\", np.round(U2,2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 Machine learning\n",
    "\n",
    "a) In meachine learning we want to create an alogrithm that finds a pattern in our data. To do that, we split our data set in two parts (a training set and a test set). The training set contains 2/3, and the test set contains 1/3 of our data points, both part must to be representative of the data. We use the training set to teach it how to find the results we want (find the pattern). While doing this, the test set is hidden. After teaching the training set, we use the alogrith on the test set. It is important to be aware that the test-error and training error is not necassery the same. Training error is the error we get when we use the alogrithm on the training data again, and the test error is the error we get when we use the trained algorithm on the test data that is has never been exposed to. Error is further described in the next part-question.\n",
    "\n",
    "\n",
    "b) Typically, a machine learning algorithm include a parameter adjusting the complexity of your model. Complexity is a number of features we use in the training data to predict our outcome. If this complexity is too simple, the algorithm is underfitting. This results in a large train error, and a large test error (illustrated in figure below). If the complxity is too complex, the algorithm is overfitting. This results in a small train error and a large test error (illustrated in figure below). We want to find the \"Sweet spot\", where the model complexity that gives smallest test error. \n",
    "\n",
    "<img src=\"4.png\" alt=\"Error\"\n",
    "\ttitle=\"Error\" width=\"450\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 Time-series analysis and Fourier transformation \n",
    "\n",
    "a) Ordinary least square method\n",
    "\n",
    "To test if there is a significant trend in $X_t$, I would use a ordinary least square method to find the necessary variable to make a linear regression. The goal in linear regression is to make a function that fit the data. This function that is made is a line ($Y = \\alpha + \\beta T$) through the data point. \n",
    "\n",
    "Further, I would use a linear regression method to test if the trend is significant (The slope $\\beta$) \n",
    "\n",
    "$$H_0 = \\text{No trend, } \\beta = 0  \\ \\ \\ \\ H_a = \\text{Significant trend, } \\beta \\neq 0 \\ \\ $$\n",
    "\n",
    "\n",
    "Test statstic: \n",
    "\n",
    "$t = \\frac{\\beta -0}{S_{\\beta}}$ where, \n",
    "\n",
    "$S_{\\beta} = \\frac{S}{\\sqrt{\\sum (T_i - \\bar{T_i})^2}}$, and $S= \\sqrt{\\frac{1}{n-2} \\sum (Y_i - \\hat{Y_i})^2}$\n",
    "\n",
    "$S_{\\beta}$ is the standard deviation og the coefficient $\\beta$, and S is the standard deviation of the regression. $Y_i$ and  $\\bar{T_i}$ are observed and estimated hydrologic variables. \n",
    "\n",
    "The null hypothesis is rejected if $|t| > t_{1-\\alpha /2, n-2}$\n",
    "\n",
    "\n",
    "\n",
    "b) Graph A shows the Fourier transformation of $X_t$.\n",
    "\n",
    "The time series $X_t$ are samples once per sencond. The graph illustrate peaks in the timeseries with a timeperiod of 5 seconds (peak every 5 second). The Fourier transformation of $X_t$ is given in frequency [1/s]. With peaks every 5 second, we have a frequency of 0.2 [1/s]. Graph A is thereforethe Fourier transformation of $X_t$, where we find a peak at 0.2. Graph A is symetric around 0.5, resulting in a peak at 0.8.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
